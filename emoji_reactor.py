#!/usr/bin/env python3
"""
Real-time emoji display based on camera pose, facial expression, and hand gesture detection.
"""

import cv2
import mediapipe as mp
import numpy as np
import math

# Initialize MediaPipe Solutions
mp_pose = mp.solutions.pose
mp_face_mesh = mp.solutions.face_mesh
mp_hands = mp.solutions.hands # ‡πÄ‡∏û‡∏¥‡πà‡∏°: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏°‡∏∑‡∏≠
mp_drawing = mp.solutions.drawing_utils

# Configuration
SMILE_THRESHOLD = 0.35
SAD_THRESHOLD = 0.53  
ANGRY_THRESHOLD = 0.05 
WINDOW_WIDTH = 720
WINDOW_HEIGHT = 450
EMOJI_WINDOW_SIZE = (WINDOW_WIDTH, WINDOW_HEIGHT)
HAND_RAISE_THRESHOLD = 0.05 # ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á y-axis ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏∑‡∏≠‡∏Å‡∏±‡∏ö‡πÑ‡∏´‡∏•‡πà

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏°‡∏∑‡∏≠ ---
def is_thumbs_up(landmarks):
    # ‡∏ô‡∏¥‡πâ‡∏ß‡∏´‡∏±‡∏ß‡πÅ‡∏°‡πà‡∏°‡∏∑‡∏≠ (Thumb Tip - 4) ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏ï‡πà‡∏≠ (Thumb IP - 3)
    # ‡∏ô‡∏¥‡πâ‡∏ß‡∏≠‡∏∑‡πà‡∏ô‡πÜ (8, 12, 16, 20) ‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏∏‡∏ö (‡∏õ‡∏•‡∏≤‡∏¢‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏ï‡πà‡∏≠)
    thumb_up = landmarks[4].y < landmarks[3].y
    index_down = landmarks[8].y > landmarks[7].y
    middle_down = landmarks[12].y > landmarks[11].y
    ring_down = landmarks[16].y > landmarks[15].y
    pinky_down = landmarks[20].y > landmarks[19].y
    return thumb_up and index_down and middle_down and ring_down and pinky_down

def is_love_sign(landmarks):
    # ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡πâ‡∏≠‡∏¢ (Pinky Tip - 20), ‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ (Index Tip - 8) ‡πÅ‡∏•‡∏∞‡∏ô‡∏¥‡πâ‡∏ß‡∏´‡∏±‡∏ß‡πÅ‡∏°‡πà‡∏°‡∏∑‡∏≠ (Thumb Tip - 4) ‡∏Å‡∏≤‡∏á‡∏≠‡∏≠‡∏Å
    # ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á (Middle - 12) ‡πÅ‡∏•‡∏∞ ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á (Ring - 16) ‡∏á‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤
    pinky_up = landmarks[20].y < landmarks[18].y
    index_up = landmarks[8].y < landmarks[6].y
    thumb_up = landmarks[4].x < landmarks[3].x # ‡∏Å‡∏≤‡∏á‡∏´‡∏±‡∏ß‡πÅ‡∏°‡πà‡∏°‡∏∑‡∏≠
    middle_down = landmarks[12].y > landmarks[11].y
    ring_down = landmarks[16].y > landmarks[15].y
    return pinky_up and index_up and thumb_up and middle_down and ring_down

def is_middle_finger(landmarks):
    # ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á (Middle Tip - 12) ‡∏ä‡∏µ‡πâ‡∏Ç‡∏∂‡πâ‡∏ô
    # ‡∏ô‡∏¥‡πâ‡∏ß‡∏≠‡∏∑‡πà‡∏ô‡πÜ (8, 16, 20) ‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏∏‡∏ö/‡∏á‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤
    middle_up = landmarks[12].y < landmarks[11].y and landmarks[12].y < landmarks[10].y
    index_down = landmarks[8].y > landmarks[7].y
    ring_down = landmarks[16].y > landmarks[15].y
    pinky_down = landmarks[20].y > landmarks[19].y
    return middle_up and index_down and ring_down and pinky_down

def is_rock_on(landmarks):
    # ‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ (Index Tip - 8) ‡πÅ‡∏•‡∏∞ ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡πâ‡∏≠‡∏¢ (Pinky Tip - 20) ‡∏ä‡∏µ‡πâ‡∏Ç‡∏∂‡πâ‡∏ô
    # ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á (Middle - 12) ‡πÅ‡∏•‡∏∞ ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á (Ring - 16) ‡∏á‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤
    index_up = landmarks[8].y < landmarks[7].y
    pinky_up = landmarks[20].y < landmarks[19].y
    middle_down = landmarks[12].y > landmarks[11].y
    ring_down = landmarks[16].y > landmarks[15].y
    return index_up and pinky_up and middle_down and ring_down

# Load emoji images
try:
    smiling_emoji = cv2.imread("smile.png")
    straight_face_emoji = cv2.imread("plain.png")
    # Pose
    hands_up_emoji = cv2.imread("air.png")
    # Face
    angry_emoji = cv2.imread("angry.png")
    sad_emoji = cv2.imread("sad.png")
    # Hands
    thumbs_up_emoji = cv2.imread("thumbs_up.png")
    love_sign_emoji = cv2.imread("love_sign.png")
    middle_finger_emoji = cv2.imread("middle_finger.png")
    rock_on_emoji = cv2.imread("rock_on.png")


    if any(e is None for e in [smiling_emoji, straight_face_emoji, hands_up_emoji, angry_emoji, sad_emoji, thumbs_up_emoji, love_sign_emoji, middle_finger_emoji, rock_on_emoji]):
        raise FileNotFoundError("One or more emoji files not found.")

    # Resize emojis
    emojis = {
        'SMILING': cv2.resize(smiling_emoji, EMOJI_WINDOW_SIZE),
        'STRAIGHT_FACE': cv2.resize(straight_face_emoji, EMOJI_WINDOW_SIZE),
        'HANDS_UP': cv2.resize(hands_up_emoji, EMOJI_WINDOW_SIZE),
        'ANGRY': cv2.resize(angry_emoji, EMOJI_WINDOW_SIZE),
        'SAD': cv2.resize(sad_emoji, EMOJI_WINDOW_SIZE),
        'THUMBS_UP': cv2.resize(thumbs_up_emoji, EMOJI_WINDOW_SIZE),
        'LOVE_SIGN': cv2.resize(love_sign_emoji, EMOJI_WINDOW_SIZE),
        'MIDDLE_FINGER': cv2.resize(middle_finger_emoji, EMOJI_WINDOW_SIZE),
        'ROCK_ON': cv2.resize(rock_on_emoji, EMOJI_WINDOW_SIZE),
    }

except Exception as e:
    print("Error loading emoji images!")
    print(f"Details: {e}")
    print("\nExpected files:")
    print("- smile.jpg, plain.png, air.jpg")
    print("- angry.png, sad.png")
    print("- thumbs_up.png, love_sign.png, middle_finger.png, rock_on.png")
    exit()

blank_emoji = np.zeros((EMOJI_WINDOW_SIZE[0], EMOJI_WINDOW_SIZE[1], 3), dtype=np.uint8)

# Start webcam
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("Error: Could not open webcam.")
    exit()

cv2.namedWindow('Emoji Output', cv2.WINDOW_NORMAL)
cv2.namedWindow('Camera Feed', cv2.WINDOW_NORMAL)
cv2.resizeWindow('Camera Feed', WINDOW_WIDTH, WINDOW_HEIGHT)
cv2.resizeWindow('Emoji Output', WINDOW_WIDTH, WINDOW_HEIGHT)
cv2.moveWindow('Camera Feed', 100, 100)
cv2.moveWindow('Emoji Output', WINDOW_WIDTH + 150, 100)

print("Controls:")
print("  Press 'q' to quit")
print("  Raise hands above shoulders for HANDS UP")
print("  Make gestures like THUMBS UP, LOVE, MIDDLE FINGER, ROCK ON")
print("  Change facial expressions for SMILING, ANGRY, SAD")

with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose, \
     mp_face_mesh.FaceMesh(max_num_faces=1, min_detection_confidence=0.5) as face_mesh, \
     mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands: # ‡πÄ‡∏û‡∏¥‡πà‡∏°: Hands Detector

    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            continue

        frame = cv2.flip(frame, 1)
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image_rgb.flags.writeable = False

        current_state = "STRAIGHT_FACE"
        
        # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏°‡∏∑‡∏≠ (Hand Gestures)
        results_hands = hands.process(image_rgb)
        if results_hands.multi_hand_landmarks:
            for hand_landmarks in results_hands.multi_hand_landmarks:
                landmarks = hand_landmarks.landmark
                
                if is_middle_finger(landmarks):
                    current_state = "MIDDLE_FINGER"
                    break
                elif is_love_sign(landmarks):
                    current_state = "LOVE_SIGN"
                    break
                elif is_rock_on(landmarks):
                    current_state = "ROCK_ON"
                    break
                elif is_thumbs_up(landmarks):
                    current_state = "THUMBS_UP"
                    break
        
        # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢ (Pose) - ‡πÄ‡∏ä‡πá‡∏Ñ Hands Up (‡∏¢‡∏Å‡∏°‡∏∑‡∏≠)
        if current_state == "STRAIGHT_FACE": # ‡∏ñ‡πâ‡∏≤‡∏°‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÉ‡∏´‡πâ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢
            results_pose = pose.process(image_rgb)
            if results_pose.pose_landmarks:
                landmarks = results_pose.pose_landmarks.landmark
                
                left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]
                right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]
                left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST]
                right_wrist = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST]

                # ‡∏¢‡∏Å‡∏°‡∏∑‡∏≠‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡πÑ‡∏´‡∏•‡πà (‡πÉ‡∏ô‡πÅ‡∏Å‡∏ô Y)
                if (left_wrist.y < left_shoulder.y - HAND_RAISE_THRESHOLD) or \
                   (right_wrist.y < right_shoulder.y - HAND_RAISE_THRESHOLD):
                    current_state = "HANDS_UP"
        
        # 3. ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏™‡∏µ‡∏´‡∏ô‡πâ‡∏≤ (Facial Expression)
        if current_state == "STRAIGHT_FACE": # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏°‡∏∑‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢ ‡πÉ‡∏´‡πâ‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏µ‡∏´‡∏ô‡πâ‡∏≤
            results_face = face_mesh.process(image_rgb)
            if results_face.multi_face_landmarks:
                for face_landmarks in results_face.multi_face_landmarks:
                    # ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SMILE
                    left_corner = face_landmarks.landmark[291]
                    right_corner = face_landmarks.landmark[61]
                    upper_lip = face_landmarks.landmark[13]
                    lower_lip = face_landmarks.landmark[14]
                    # ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ANGRY (‡∏Ñ‡∏¥‡πâ‡∏ß)
                    left_inner_brow = face_landmarks.landmark[52]
                    right_inner_brow = face_landmarks.landmark[282]
                    left_outer_brow = face_landmarks.landmark[55]
                    right_outer_brow = face_landmarks.landmark[285]
                    # ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏≠‡∏∑‡πà‡∏ô‡πÜ
                    
                    mouth_width = ((right_corner.x - left_corner.x)**2 + (right_corner.y - left_corner.y)**2)**0.5
                    mouth_height = ((lower_lip.x - upper_lip.x)**2 + (lower_lip.y - upper_lip.y)**2)**0.5
                    
                    if mouth_width > 0:
                        mouth_aspect_ratio = mouth_height / mouth_width

                        # --- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö ANGRY ---
                        left_brow_diff = left_outer_brow.y - left_inner_brow.y
                        right_brow_diff = right_outer_brow.y - right_inner_brow.y
                        if left_brow_diff < ANGRY_THRESHOLD and right_brow_diff < ANGRY_THRESHOLD:
                            current_state = "ANGRY"
                            
                        # --- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö SAD ---
                        # ‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏≤‡∏Å‡∏õ‡∏¥‡∏î, ‡πÑ‡∏°‡πà‡∏¢‡∏¥‡πâ‡∏°, ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏õ‡∏≤‡∏Å/‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏õ‡∏≤‡∏Å‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥
                        elif mouth_aspect_ratio < SAD_THRESHOLD and mouth_height < 0.01:
                            # ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏≤‡∏Å‡∏Ñ‡∏ß‡πà‡∏≥/‡∏ö‡∏∂‡πâ‡∏á (‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ SAD_THRESHOLD ‡πÑ‡∏î‡πâ)
                            current_state = "SAD"
                        
                        # --- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö SMILING ---
                        elif mouth_aspect_ratio > SMILE_THRESHOLD:
                            current_state = "SMILING"
                        
                        # --- ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏õ‡∏Å‡∏ï‡∏¥ ---
                        else:
                            current_state = "STRAIGHT_FACE"
                        
        # 4. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Emoji ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        emoji_map = {
            "SMILING": "üòä", "STRAIGHT_FACE": "üòê", "ANGRY": "üò†", "SAD": "üò¢", 
            "HANDS_UP": "üôå", "THUMBS_UP": "üëç", "LOVE_SIGN": "ü§ü", 
            "MIDDLE_FINGER": "üñï", "ROCK_ON": "ü§ò"
        }
        
        emoji_to_display = emojis.get(current_state, blank_emoji)
        emoji_name = emoji_map.get(current_state, "‚ùì")

        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ö‡∏ô‡∏à‡∏≠ Camera Feed
        camera_frame_resized = cv2.resize(frame, (WINDOW_WIDTH, WINDOW_HEIGHT))
        
        cv2.putText(camera_frame_resized, f'STATE: {current_state} {emoji_name}', (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)
        cv2.putText(camera_frame_resized, 'Press "q" to quit', (10, WINDOW_HEIGHT - 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)

        cv2.imshow('Camera Feed', camera_frame_resized)
        cv2.imshow('Emoji Output', emoji_to_display)

        if cv2.waitKey(5) & 0xFF == ord('q'):
            break

cap.release()
cv2.destroyAllWindows()